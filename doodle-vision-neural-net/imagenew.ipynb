{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e9f129",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578b631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cat drawings\n",
      "loading cat drawings\n",
      "load complete\n",
      "Loading dog drawings\n",
      "loading dog drawings\n",
      "load complete\n",
      "Loading tree drawings\n",
      "loading tree drawings\n",
      "load complete\n",
      "Loading house drawings\n",
      "loading house drawings\n",
      "load complete\n",
      "Loading car drawings\n",
      "loading car drawings\n",
      "load complete\n",
      "Loading apple drawings\n",
      "loading apple drawings\n",
      "load complete\n",
      "Loading chair drawings\n",
      "loading chair drawings\n",
      "load complete\n",
      "Loading bird drawings\n",
      "loading bird drawings\n",
      "load complete\n",
      "Loading fish drawings\n",
      "loading fish drawings\n",
      "load complete\n",
      "Loading flower drawings\n",
      "loading flower drawings\n",
      "load complete\n",
      "load complete\n",
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.2672 - loss: 2.0559 - val_accuracy: 0.5755 - val_loss: 1.3269\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5686 - loss: 1.2965 - val_accuracy: 0.6915 - val_loss: 0.9472\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6697 - loss: 0.9840 - val_accuracy: 0.7325 - val_loss: 0.7720\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7372 - loss: 0.8025 - val_accuracy: 0.7650 - val_loss: 0.7099\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7622 - loss: 0.7255 - val_accuracy: 0.7930 - val_loss: 0.6232\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7946 - loss: 0.6231 - val_accuracy: 0.7890 - val_loss: 0.6204\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8056 - loss: 0.5833 - val_accuracy: 0.8175 - val_loss: 0.5599\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8198 - loss: 0.5335 - val_accuracy: 0.8270 - val_loss: 0.5264\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8431 - loss: 0.4790 - val_accuracy: 0.8335 - val_loss: 0.5154\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8469 - loss: 0.4567 - val_accuracy: 0.8380 - val_loss: 0.5120\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from quickdraw import QuickDrawDataGroup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "CATEGORIES = [\"cat\", \"dog\", \"tree\", \"house\", \"car\", \"apple\", \"chair\", \"bird\", \"fish\", \"flower\"]\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "IMG_SIZE = (28, 28)\n",
    "IMAGES_PER_CATEGORY = 1000\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    x_data, y_data = [], []\n",
    "    for idx, category in enumerate(CATEGORIES):\n",
    "        print(f\"Loading {category} drawings\")\n",
    "        qd_group = QuickDrawDataGroup(category, max_drawings=IMAGES_PER_CATEGORY, recognized=True)\n",
    "        images = [255 - np.array(d.get_image(stroke_width=3).resize(IMG_SIZE).convert(\"L\")) for d in qd_group.drawings]\n",
    "        x_data.extend(images)\n",
    "        y_data.extend([idx] * len(images))\n",
    "    x = np.array(x_data).reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    y = tf.keras.utils.to_categorical(y_data, NUM_CLASSES)\n",
    "    print(\"load complete\")\n",
    "    return train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_and_train_model():\n",
    "    x_train, x_test, y_train, y_test = load_and_preprocess_data()\n",
    "    inputs = layers.Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu', name='feature_layer')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
    "\n",
    "    feature_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('feature_layer').output)\n",
    "    x_features = feature_model.predict(x_test)\n",
    "    pca = PCA(n_components=2)\n",
    "    x_tsne = pca.fit_transform(x_features)\n",
    "    return model, feature_model, x_test, y_test, pca, x_tsne\n",
    "\n",
    "class ObjectRecognizerApp:\n",
    "    def __init__(self, root, model, feature_model, x_test, y_test, pca, x_tsne):\n",
    "        self.model = model\n",
    "        self.feature_model = feature_model\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.pca = pca\n",
    "        self.x_tsne = x_tsne\n",
    "        self.root = root\n",
    "\n",
    "        self.canvas = tk.Canvas(root, width=200, height=200, bg='white')\n",
    "        self.canvas.pack()\n",
    "        tk.Button(root, text=\"Predict\", command=self.predict_object).pack()\n",
    "        tk.Button(root, text=\"Clear\", command=self.clear_canvas).pack()\n",
    "        tk.Button(root, text=\"Open Doodle Dialog\", command=self.open_doodle_dialog).pack()\n",
    "        self.result_label = tk.Label(root, text=\"Draw and Predict\")\n",
    "        self.result_label.pack()\n",
    "\n",
    "        self.image = Image.new(\"L\", (200, 200), 255)\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "        self.last_x, self.last_y = None, None\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_line)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.reset_last)\n",
    "\n",
    "    def draw_line(self, event):\n",
    "        if self.last_x is not None and self.last_y is not None:\n",
    "            self.canvas.create_line(self.last_x, self.last_y, event.x, event.y, width=10, fill='black')\n",
    "            self.draw.line([self.last_x, self.last_y, event.x, event.y], fill=0, width=10)\n",
    "        self.last_x, self.last_y = event.x, event.y\n",
    "\n",
    "    def reset_last(self, event):\n",
    "        self.last_x, self.last_y = None, None\n",
    "\n",
    "    def clear_canvas(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.image = Image.new(\"L\", (200, 200), 255)\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "        self.result_label.config(text=\"Draw and Predict\")\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        img = image.resize((28, 28))\n",
    "        img_array = 255 - np.array(img)\n",
    "        img_array = img_array.astype('float32') / 255\n",
    "        return img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "    def predict_object(self):\n",
    "        img_array = self.preprocess_image(self.image)\n",
    "        prediction = self.model.predict(img_array)\n",
    "        idx = np.argmax(prediction)\n",
    "        self.result_label.config(text=f\"Predicted: {CATEGORIES[idx]} ({np.max(prediction):.2%})\")\n",
    "\n",
    "    def open_doodle_dialog(self):\n",
    "        dialog = tk.Toplevel(self.root)\n",
    "        dialog.geometry(\"900x600\")\n",
    "        canvas = tk.Canvas(dialog, width=200, height=200, bg='white')\n",
    "        canvas.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        image = Image.new(\"L\", (200, 200), 255)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        last = {\"x\": None, \"y\": None}\n",
    "\n",
    "        def draw_line(event):\n",
    "            if last[\"x\"] is not None and last[\"y\"] is not None:\n",
    "                canvas.create_line(last[\"x\"], last[\"y\"], event.x, event.y, width=10, fill='black')\n",
    "                draw.line([last[\"x\"], last[\"y\"], event.x, event.y], fill=0, width=10)\n",
    "            last[\"x\"], last[\"y\"] = event.x, event.y\n",
    "\n",
    "        def reset_last(event):\n",
    "            last[\"x\"], last[\"y\"] = None, None\n",
    "\n",
    "        canvas.bind(\"<B1-Motion>\", draw_line)\n",
    "        canvas.bind(\"<ButtonRelease-1>\", reset_last)\n",
    "        label = tk.Label(dialog, text=\"Draw and Predict\")\n",
    "        label.pack()\n",
    "\n",
    "        def predict_and_visualize():\n",
    "            arr = self.preprocess_image(image)\n",
    "            pred = self.model.predict(arr)\n",
    "            idx = np.argmax(pred)\n",
    "            label.config(text=f\"Predicted: {CATEGORIES[idx]} ({np.max(pred):.2%})\")\n",
    "            features = self.feature_model.predict(arr)\n",
    "            self.display_plot_in_dialog(dialog, features, CATEGORIES[idx])\n",
    "\n",
    "        tk.Button(dialog, text=\"Predict and Visualize\", command=predict_and_visualize).pack()\n",
    "        tk.Button(dialog, text=\"Clear\", command=lambda: [canvas.delete(\"all\"), image.paste(255, (0,0,200,200))]).pack()\n",
    "\n",
    "    def display_plot_in_dialog(self, parent, doodle_features, doodle_label):\n",
    "        all_features = np.vstack([self.feature_model.predict(self.x_test), doodle_features])\n",
    "        all_tsne = self.pca.fit_transform(all_features)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        cmap = cm.get_cmap('tab10', len(CATEGORIES))\n",
    "        colors = [to_hex(cmap(i)) for i in range(len(CATEGORIES))]\n",
    "\n",
    "        for i, cat in enumerate(CATEGORIES):\n",
    "            mask = np.argmax(self.y_test, axis=1) == i\n",
    "            pts = all_tsne[mask]\n",
    "            ax.scatter(pts[:, 0], pts[:, 1], label=cat, s=30, alpha=0.6, edgecolors='w', linewidths=0.5, color=colors[i])\n",
    "            if len(pts) >= 3:\n",
    "                hull = ConvexHull(pts)\n",
    "                polygon = Polygon(pts[hull.vertices], closed=True, edgecolor=colors[i], facecolor=colors[i], alpha=0.08)\n",
    "                ax.add_patch(polygon)\n",
    "\n",
    "        ax.scatter(all_tsne[-1, 0], all_tsne[-1, 1], marker='*', s=300, c='black', edgecolors='yellow', linewidths=2, zorder=10, label=f\"Doodle: {doodle_label}\")\n",
    "        ax.set_title(\"Your Doodle in Feature Space\", fontsize=14)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        canvas_frame = tk.Frame(parent)\n",
    "        canvas_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "        canvas = FigureCanvasTkAgg(fig, master=canvas_frame)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "model, feature_model, x_test, y_test, pca, x_tsne = build_and_train_model()\n",
    "root = tk.Tk()\n",
    "app = ObjectRecognizerApp(root, model, feature_model, x_test, y_test, pca, x_tsne)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artificialneuralnetworks2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
